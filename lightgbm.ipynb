{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0cd5f46e3198f519a965fc62690decb9b80581385622b2bc0fa17348340787f1f",
   "display_name": "Python 3.8.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "cd5f46e3198f519a965fc62690decb9b80581385622b2bc0fa17348340787f1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# LightGBM Implementation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Download Requirements"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: numerapi in c:\\users\\edward tang\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (2.4.2)\n",
      "Collecting catboost\n",
      "  Downloading catboost-0.25.1-cp38-none-win_amd64.whl (66.9 MB)\n",
      "Requirement already satisfied: xgboost in c:\\users\\edward tang\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (1.4.1)\n",
      "Collecting lightgbm\n",
      "  Downloading lightgbm-3.2.1-py3-none-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\edward tang\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from catboost) (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\edward tang\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from catboost) (1.19.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\edward tang\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from catboost) (1.5.2)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.16-py2.py3-none-any.whl (19 kB)\n",
      "Collecting plotly\n",
      "  Downloading plotly-4.14.3-py2.py3-none-any.whl (13.2 MB)\n",
      "Requirement already satisfied: six in c:\\users\\edward tang\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from catboost) (1.15.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\edward tang\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from catboost) (3.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\edward tang\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\edward tang\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from pandas>=0.24.0->catboost) (2020.1)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\edward tang\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from lightgbm) (0.23.2)\n",
      "Requirement already satisfied: wheel in c:\\users\\edward tang\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from lightgbm) (0.36.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\edward tang\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from scikit-learn!=0.22.0->lightgbm) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\edward tang\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
      "Requirement already satisfied: tqdm>=4.29.1 in c:\\users\\edward tang\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from numerapi) (4.58.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\edward tang\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from numerapi) (7.1.2)\n",
      "Requirement already satisfied: requests in c:\\users\\edward tang\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from numerapi) (2.24.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\edward tang\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\edward tang\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\edward tang\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from matplotlib->catboost) (7.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\edward tang\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\edward tang\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from matplotlib->catboost) (2020.6.20)\n",
      "Collecting retrying>=1.3.3\n",
      "  Downloading retrying-1.3.3.tar.gz (10 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\edward tang\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from requests->numerapi) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\edward tang\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from requests->numerapi) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\edward tang\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from requests->numerapi) (3.0.4)\n",
      "Building wheels for collected packages: retrying\n",
      "  Building wheel for retrying (setup.py): started\n",
      "  Building wheel for retrying (setup.py): finished with status 'done'\n",
      "  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11429 sha256=b3ca07c5b6c77be89da82f5ed413a02a93dda0fcd27c920a4ac3405872ad81e5\n",
      "  Stored in directory: c:\\users\\edward tang\\appdata\\local\\pip\\cache\\wheels\\c4\\a7\\48\\0a434133f6d56e878ca511c0e6c38326907c0792f67b476e56\n",
      "Successfully built retrying\n",
      "Installing collected packages: retrying, plotly, graphviz, lightgbm, catboost\n",
      "Successfully installed catboost-0.25.1 graphviz-0.16 lightgbm-3.2.1 plotly-4.14.3 retrying-1.3.3\n",
      "Submodule path 'external_libs/compute': checked out '36c89134d4013b2e5e45bc55656a18bd6141995a'\n",
      "Submodule path 'external_libs/eigen': checked out '8ba1b0f41a7950dc3e1d4ed75859e36c73311235'\n",
      "Submodule path 'external_libs/fast_double_parser': checked out 'ace60646c02dc54c57f19d644e49a61e7e7758ec'\n",
      "Submodule path 'external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp': checked out 'd936052d32a5b7ca08b0199a6724724aea432309'\n",
      "Submodule path 'external_libs/fast_double_parser/benchmarks/dependencies/double-conversion': checked out 'f4cb2384efa55dee0e6652f8674b05763441ab09'\n",
      "Submodule path 'external_libs/fmt': checked out 'cc09f1a6798c085c325569ef466bcdcffdc266d4'\n",
      "[WinError 3] The system cannot find the path specified: '/content/LightGBM'\n",
      "C:\\Users\\Edward Tang\\AppData\\Local\\Programs\\Microsoft VS Code\n",
      "Cloning into 'LightGBM'...\n",
      "Submodule 'include/boost/compute' (https://github.com/boostorg/compute) registered for path 'external_libs/compute'\n",
      "Submodule 'eigen' (https://gitlab.com/libeigen/eigen.git) registered for path 'external_libs/eigen'\n",
      "Submodule 'external_libs/fast_double_parser' (https://github.com/lemire/fast_double_parser.git) registered for path 'external_libs/fast_double_parser'\n",
      "Submodule 'external_libs/fmt' (https://github.com/fmtlib/fmt.git) registered for path 'external_libs/fmt'\n",
      "Cloning into 'C:/Users/Edward Tang/AppData/Local/Programs/Microsoft VS Code/LightGBM/external_libs/compute'...\n",
      "Cloning into 'C:/Users/Edward Tang/AppData/Local/Programs/Microsoft VS Code/LightGBM/external_libs/eigen'...\n",
      "Cloning into 'C:/Users/Edward Tang/AppData/Local/Programs/Microsoft VS Code/LightGBM/external_libs/fast_double_parser'...\n",
      "Cloning into 'C:/Users/Edward Tang/AppData/Local/Programs/Microsoft VS Code/LightGBM/external_libs/fmt'...\n",
      "Submodule 'benchmark/dependencies/abseil-cpp' (https://github.com/abseil/abseil-cpp.git) registered for path 'external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp'\n",
      "Submodule 'benchmark/dependencies/double-conversion' (https://github.com/google/double-conversion.git) registered for path 'external_libs/fast_double_parser/benchmarks/dependencies/double-conversion'\n",
      "Cloning into 'C:/Users/Edward Tang/AppData/Local/Programs/Microsoft VS Code/LightGBM/external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp'...\n",
      "Cloning into 'C:/Users/Edward Tang/AppData/Local/Programs/Microsoft VS Code/LightGBM/external_libs/fast_double_parser/benchmarks/dependencies/double-conversion'...\n",
      "'cmake' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'make' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'sudo' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "[WinError 3] The system cannot find the path specified: '/content/LightGBM/python-package'\n",
      "C:\\Users\\Edward Tang\\AppData\\Local\\Programs\\Microsoft VS Code\n",
      "'sudo' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'sudo' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!pip install numerapi catboost xgboost lightgbm catboost\n",
    "!git clone --recursive https://github.com/Microsoft/LightGBM\n",
    "%cd /content/LightGBM\n",
    "!mkdir build\n",
    "!cmake -DUSE_GPU=1\n",
    "!make -j$(nproc)\n",
    "!sudo apt-get -y install python-pip\n",
    "!sudo -H pip install setuptools pandas numpy scipy scikit-learn -U\n",
    "%cd /content/LightGBM/python-package\n",
    "!sudo python setup.py install --precompile"
   ]
  },
  {
   "source": [
    "## Import Requirements"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "import numerapi, warnings\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "source": [
    "# Numerapi Setup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "In progress.\n"
     ]
    }
   ],
   "source": [
    "public_id = 'QPRBQANL6KUXWTXPQLDHHJIZ2OYGEBNA'\n",
    "secret_key = ':)'\n",
    "napi = numerapi.NumerAPI(public_id=public_id, secret_key=secret_key)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "leaderboard = napi.get_leaderboard()\n",
    "# check if a new round has started\n",
    "\n",
    "try:\n",
    "  if napi.check_new_round():\n",
    "    print(\"Ready.\")\n",
    "  else:\n",
    "    print(\"In progress.\")\n",
    "except:\n",
    "  print(\"Not ready.\")"
   ]
  },
  {
   "source": [
    "## Download Training and Tournament Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Thu Apr 22 13:29:06 2021] Downloading the lastest training data set. Current round is: 260...\n",
      "\n",
      "[Thu Apr 22 13:30:02 2021] Training dataset has been loaded. It took 56.37 seconds\n",
      "[Thu Apr 22 13:30:02 2021] Downloading the lastest tournament data set. Current round is: 260...\n",
      "\n",
      "[Thu Apr 22 13:32:53 2021] Tournament dataset has been loaded. It took 171.37 seconds\n"
     ]
    }
   ],
   "source": [
    "# Download Training Data From Numerai\n",
    "start = time.time()\n",
    "print(f\"[{time.asctime()}] Downloading the lastest training data set. Current round is: {numerapi.NumerAPI(verbosity='info').get_current_round()}...\\n\")\n",
    "training_data = pd.read_csv(\"https://numerai-public-datasets.s3-us-west-2.amazonaws.com/latest_numerai_training_data.csv.xz\", header=0)\n",
    "end = time.time()\n",
    "print(f\"[{time.asctime()}] Training dataset has been loaded. It took {end - start:0.2f} seconds\")\n",
    "\n",
    "# Download Tournament Data From Numerai\n",
    "start = time.time()\n",
    "print(f\"[{time.asctime()}] Downloading the lastest tournament data set. Current round is: {numerapi.NumerAPI(verbosity='info').get_current_round()}...\\n\")\n",
    "tournament_data = pd.read_csv(\"https://numerai-public-datasets.s3-us-west-2.amazonaws.com/latest_numerai_tournament_data.csv.xz\", header=0)\n",
    "end = time.time()\n",
    "print(f\"[{time.asctime()}] Tournament dataset has been loaded. It took {end - start:0.2f} seconds\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                      id     era data_type  feature_intelligence1  \\\n0       n000315175b67977    era1     train                   0.00   \n1       n0014af834a96cdd    era1     train                   0.00   \n2       n001c93979ac41d4    era1     train                   0.25   \n3       n0034e4143f22a13    era1     train                   1.00   \n4       n00679d1a636062f    era1     train                   0.25   \n...                  ...     ...       ...                    ...   \n501803  nff6a8a8feaeeb52  era120     train                   0.50   \n501804  nff6af62a0996372  era120     train                   1.00   \n501805  nff9288983b8c040  era120     train                   0.75   \n501806  nffaab4e1cacc4b1  era120     train                   0.25   \n501807  nffba5460b572cfa  era120     train                   0.75   \n\n        feature_intelligence2  feature_intelligence3  feature_intelligence4  \\\n0                        0.50                   0.25                   0.00   \n1                        0.00                   0.00                   0.25   \n2                        0.50                   0.25                   0.25   \n3                        0.00                   0.00                   0.50   \n4                        0.25                   0.25                   0.25   \n...                       ...                    ...                    ...   \n501803                   0.50                   0.25                   0.00   \n501804                   0.00                   0.00                   1.00   \n501805                   0.50                   0.50                   0.50   \n501806                   0.25                   0.25                   0.50   \n501807                   0.50                   0.50                   0.75   \n\n        feature_intelligence5  feature_intelligence6  feature_intelligence7  \\\n0                        0.50                   0.25                   0.25   \n1                        0.50                   0.00                   0.00   \n2                        1.00                   0.75                   0.75   \n3                        0.50                   0.25                   0.25   \n4                        0.00                   0.25                   0.50   \n...                       ...                    ...                    ...   \n501803                   0.00                   0.50                   0.75   \n501804                   0.50                   0.75                   0.75   \n501805                   0.25                   0.50                   0.25   \n501806                   0.00                   1.00                   1.00   \n501807                   0.75                   0.00                   0.00   \n\n        ...  feature_wisdom38  feature_wisdom39  feature_wisdom40  \\\n0       ...              1.00              1.00              0.75   \n1       ...              1.00              1.00              0.00   \n2       ...              0.25              0.50              0.00   \n3       ...              1.00              1.00              0.75   \n4       ...              0.75              0.75              0.25   \n...     ...               ...               ...               ...   \n501803  ...              0.50              0.50              0.75   \n501804  ...              1.00              1.00              1.00   \n501805  ...              1.00              0.75              0.25   \n501806  ...              0.75              0.75              0.75   \n501807  ...              0.50              0.50              0.25   \n\n        feature_wisdom41  feature_wisdom42  feature_wisdom43  \\\n0                   0.50              0.75              0.50   \n1                   0.00              0.75              0.25   \n2                   0.00              0.50              1.00   \n3                   0.75              1.00              1.00   \n4                   0.50              0.75              0.00   \n...                  ...               ...               ...   \n501803              0.50              0.50              0.75   \n501804              1.00              1.00              0.00   \n501805              1.00              1.00              1.00   \n501806              0.75              0.75              0.50   \n501807              0.50              0.75              1.00   \n\n        feature_wisdom44  feature_wisdom45  feature_wisdom46  target  \n0                   1.00              0.50              0.75    0.50  \n1                   0.00              0.25              1.00    0.25  \n2                   0.00              0.25              0.75    0.25  \n3                   0.75              1.00              1.00    0.25  \n4                   0.50              0.25              0.75    0.75  \n...                  ...               ...               ...     ...  \n501803              0.25              0.25              0.25    0.50  \n501804              0.75              1.00              1.00    0.75  \n501805              0.25              0.00              0.00    0.25  \n501806              0.50              0.25              0.75    0.50  \n501807              0.25              0.75              0.50    0.50  \n\n[501808 rows x 314 columns]\n"
     ]
    }
   ],
   "source": [
    "print(training_data)"
   ]
  },
  {
   "source": [
    "## Defining Preprocessing Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encode strings to id values\n",
    "def labelencode(col, df_train, df_test):\n",
    "  le = preprocessing.LabelEncoder()\n",
    "  le.fit(list(df_train[col].values) + list(df_test[col].values))\n",
    "  df_train[col] = le.transform(df_train[col])\n",
    "  df_test[col] = le.transform(df_test[col])\n",
    "\n",
    "# preprocess non-categorical columns to integers\n",
    "def preprocess(df_orig):\n",
    "  df = df_orig.copy()\n",
    "  c = list(set(df.columns) - set(['era', 'data_type']))\n",
    "  df[c] = (df[c] * 4).astype(np.int32)\n",
    "  df['era'] = df['era'].astype('category')\n",
    "  df['data_type'] = df['data_type'].astype('category')\n",
    "  return df\n",
    "\n",
    "# scaling for making output values between 0 and 1\n",
    "def scale(arr, minv, maxv):\n",
    "  return np.interp(arr, (np.min(arr), np.max(arr)), (minv, maxv))\n"
   ]
  },
  {
   "source": [
    "## Preprocess Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencode('era', training_data, tournament_data)\n",
    "labelencode('data_type', training_data, tournament_data)\n",
    "\n",
    "# store and scale target values\n",
    "y_tr = training_data['target']\n",
    "y_tr_int = (training_data['target'] * 4).astype(np.int32)\n",
    "\n",
    "# store id for submission\n",
    "id_val = tournament_data['id']\n",
    "\n",
    "# isolate the features from the dataset\n",
    "training_data.drop(['target', 'id'], axis=1, inplace=True)\n",
    "df_tr_processed = preprocess(training_data)\n",
    "\n",
    "tournament_data.drop(['target', 'id'], axis=1, inplace=True)\n",
    "df_te_processed = preprocess(tournament_data)\n"
   ]
  },
  {
   "source": [
    "## Define LightGBM Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df_tr_processed' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c3a530e6f32d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mFEATURE_DROPOUT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.03\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mf_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_tr_processed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_tr_processed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'feature'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mf_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_tr_processed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_tr_processed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'feature'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_tr_processed' is not defined"
     ]
    }
   ],
   "source": [
    "# lightGBM parameters\n",
    "params_l = {\n",
    "    'objective':'mse',\n",
    "    'boosting_type':'gbrt',\n",
    "    'metric':'mse',\n",
    "    'device_type':'gpu',\n",
    "    'max_depth': 10\n",
    "}\n",
    "\n",
    "N_EPOCH = 15\n",
    "N_FOLD = 15\n",
    "FEATURE_DROPOUT = 0.03\n",
    "\n",
    "f_c = list(df_tr_processed.columns[df_tr_processed.columns.str.startswith('feature')])\n",
    "f_l = list(df_tr_processed.columns[df_tr_processed.columns.str.startswith('feature')])\n",
    "preds = []\n",
    "for i in range(N_EPOCH):\n",
    "  pred_l = np.zeros(len(tournament_data))\n",
    "  folds = KFold(n_splits=N_FOLD)\n",
    "  for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_tr_processed[f_l], y_tr_int)):\n",
    "    tr_x, tr_y = df_tr_processed[f_l].iloc[trn_idx,:], y_tr_int[trn_idx]\n",
    "    vl_x, vl_y = df_tr_processed[f_l].iloc[val_idx,:], y_tr_int[val_idx]\n",
    "\n",
    "    print('EPOCH {}/{} | LGBM FOLD {}/{}'.format(i+1, N_EPOCH, fold_+1, N_FOLD))\n",
    "    tr_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "    vl_data = lgb.Dataset(vl_x, label=vl_y)  \n",
    "    m_l = lgb.train(\n",
    "        params_l,\n",
    "        tr_data,\n",
    "        valid_sets = [tr_data, vl_data],\n",
    "        verbose_eval = 200,\n",
    "    )\n",
    "\n",
    "    # prediction within the fold\n",
    "    pred_l += m_l.predict(df_te_processed[f_l])/N_FOLD\n",
    "\n",
    "    # reversing the integer transformation\n",
    "    pred_l *= 0.25\n",
    "\n",
    "    # reduce features by importance\n",
    "    f_imp = pd.DataFrame(sorted(zip(m_l.feature_importance(),\n",
    "                                    df_tr_processed[f_l].columns)),\n",
    "                        columns=['Value', 'Feature'])\n",
    "    col_drop = int(len(f_imp) * FEATURE_DROPOUT)\n",
    "    f_l = list(f_imp[col_drop:]['Feature'].values)\n",
    "    \n",
    "    print(f_imp)\n",
    "\n",
    "  # store predictions for epoch\n",
    "  preds.append(pred_l)\n",
    "\n",
    "# average and scale predictions\n",
    "preds = np.mean(preds, axis=0)\n",
    "preds = scale(preds, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.54508255 0.57272139 0.76138928 ... 0.66742899 0.57047033 0.6628438 ]\n"
     ]
    }
   ],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Submission Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 id  prediction\n",
       "0  n0003aa52cab36c2    0.545083\n",
       "1  n000920ed083903f    0.572721\n",
       "2  n0038e640522c4a6    0.761389\n",
       "3  n004ac94a87dc54b    0.580801\n",
       "4  n0052fe97ea0c05f    0.610046"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>n0003aa52cab36c2</td>\n      <td>0.545083</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>n000920ed083903f</td>\n      <td>0.572721</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>n0038e640522c4a6</td>\n      <td>0.761389</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>n004ac94a87dc54b</td>\n      <td>0.580801</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>n0052fe97ea0c05f</td>\n      <td>0.610046</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# submission datafram\n",
    "column = ['id','prediction']\n",
    "\n",
    "df = pd.DataFrame(columns = column)\n",
    "df['prediction'] = preds\n",
    "df['id'] = id_val\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "## Submission and File Creation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-04-21 21:56:07,776 INFO numerapi.base_api: uploading predictions...\n",
      "c3313104-83c9-411a-8b3d-03c7bcc111e5\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('./predictions.csv', index=False)\n",
    "submission_id = napi.upload_predictions('./predictions.csv')\n",
    "print(submission_id)"
   ]
  }
 ]
}