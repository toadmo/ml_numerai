{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS485_Project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python392jvsc74a57bd08fe077956e84e6b59f116a7e9738aabbdf5e9bca6b48786bc1c1513955207840",
      "display_name": "Python 3.9.2 64-bit"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.2"
    },
    "metadata": {
      "interpreter": {
        "hash": "8fe077956e84e6b59f116a7e9738aabbdf5e9bca6b48786bc1c1513955207840"
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJ-thlkU_jMa"
      },
      "source": [
        "# 1. Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iASoq88Q_PJB",
        "outputId": "a1607133-9ff1-48ac-88d8-155a0b62c51b"
      },
      "source": [
        "# Install Dependencies\n",
        "!pip install pandas sklearn numerapi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_mY2fHK_YrS"
      },
      "source": [
        "# Import Dependencies\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import numerapi, time, warnings, itertools\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LambdaCallback, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "from sklearn.model_selection import train_test_split, GroupKFold, GridSearchCV\n",
        "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import preprocessing\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "pd.set_option('chained_assignment', None)\n",
        "\n",
        "# ignore warning messages\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "## Background Functions"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_group_stats(df: pd.DataFrame) -> pd.DataFrame:\n",
        "        for group in [\"intelligence\", \"wisdom\", \"charisma\", \"dexterity\", \"strength\", \"constitution\"]:\n",
        "            cols = [col for col in df.columns if group in col]\n",
        "            df[f\"feature_{group}_mean\"] = df[cols].mean(axis=1)\n",
        "            df[f\"feature_{group}_std\"] = df[cols].std(axis=1)\n",
        "            df[f\"feature_{group}_skew\"] = df[cols].skew(axis=1)\n",
        "        return df\n",
        "\n",
        "\n",
        "def sharpe_ratio(corrs: pd.Series) -> np.float32:\n",
        "        \"\"\"\n",
        "        Calculate the Sharpe ratio for Numerai by using grouped per-era data\n",
        "\n",
        "        :param corrs: A Pandas Series containing the Spearman correlations for each era\n",
        "        :return: A float denoting the Sharpe ratio of your predictions.\n",
        "        \"\"\"\n",
        "        return corrs.mean() / corrs.std()\n",
        "\n",
        "\n",
        "def evaluate(df: pd.DataFrame) -> tuple:\n",
        "        \"\"\"\n",
        "        Evaluate and display relevant metrics for Numerai \n",
        "\n",
        "        :param df: A Pandas DataFrame containing the columns \"era\", \"target\" and a column for predictions\n",
        "        :param pred_col: The column where the predictions are stored\n",
        "        :return: A tuple of float containing the metrics\n",
        "        \"\"\"\n",
        "        def _score(sub_df: pd.DataFrame) -> np.float32:\n",
        "            \"\"\"Calculates Spearman correlation\"\"\"\n",
        "            return spearmanr(sub_df[\"target\"], sub_df[\"prediction\"])[0]\n",
        "\n",
        "        # Calculate metrics\n",
        "        corrs = df.groupby(\"era\").apply(_score)\n",
        "        print(corrs)\n",
        "        payout_raw = (corrs / 0.2).clip(-1, 1)\n",
        "        spearman = round(corrs.mean(), 4)\n",
        "\n",
        "        payout = round(payout_raw.mean(), 4)\n",
        "        numerai_sharpe = round(sharpe_ratio(corrs), 4)\n",
        "        mae = mean_absolute_error(df[\"target\"], df[\"prediction\"]).round(4)\n",
        "\n",
        "        # Display metrics\n",
        "        print(f\"Spearman Correlation: {spearman}\")\n",
        "        print(f\"Average Payout: {payout}\")\n",
        "        print(f\"Sharpe Ratio: {numerai_sharpe}\")\n",
        "        print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "        return spearman, payout, numerai_sharpe, mae"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUk0RCWXWrUP"
      },
      "source": [
        "# 2. Numerai Tournament API setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnuUeSAiWvPf"
      },
      "source": [
        "# Get your API keys and model_id from https://numer.ai/submit\n",
        "public_id = \"INSERT PUBLIC ID\"\n",
        "secret_key = \"INSERT SECRET KEY\"\n",
        "model_id = \"INSERT MODEL ID\"\n",
        "napi = numerapi.NumerAPI(public_id=public_id, secret_key=secret_key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUEh-z4D_hBK"
      },
      "source": [
        "# 3. Download Data Sets\n",
        "\n",
        "### Datasets \n",
        "*   `trainingData` is used to train the model\n",
        "*   `tournamentData` is used to evaluate the model\n",
        "\n",
        "### Column descriptions\n",
        "*   id: a randomized id that corresponds to a stock \n",
        "*   era: a period of time\n",
        "*   data_type: either `train`, `validation`, `test`, or `live` \n",
        "*   feature_*: abstract financial features of the stock \n",
        "*   target: abstract measure of stock performance\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_WfC75D_sFk"
      },
      "source": [
        "# Download Training Data From Numerai\n",
        "start = time.time()\n",
        "print(f\"[{time.asctime()}] Downloading the lastest training data set. Current round is: {numerapi.NumerAPI(verbosity='info').get_current_round()}...\\n\")\n",
        "trainingData = pd.read_csv(\"https://numerai-public-datasets.s3-us-west-2.amazonaws.com/latest_numerai_training_data.csv.xz\", header=0)\n",
        "end = time.time()\n",
        "print(f\"[{time.asctime()}] Training dataset has been loaded. It took {end - start:0.2f} seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download Tournament Data From Numerai\n",
        "start = time.time()\n",
        "print(f\"[{time.asctime()}] Downloading the lastest tournament data set. Current round is: {numerapi.NumerAPI(verbosity='info').get_current_round()}...\\n\")\n",
        "tournamentData = pd.read_csv(\"https://numerai-public-datasets.s3-us-west-2.amazonaws.com/latest_numerai_tournament_data.csv.xz\", header=0)\n",
        "end = time.time()\n",
        "print(f\"[{time.asctime()}] Tournament dataset has been loaded. It took {end - start:0.2f} seconds\")"
      ]
    },
    {
      "source": [
        "# 4. Explore The Dataset"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "AxL1hBnGD3K7",
        "outputId": "0427332d-a18f-457a-87a5-ea9f2a0fc342"
      },
      "source": [
        "# Print Training Data\n",
        "trainingData.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find Unique Items Within The Training Data\n",
        "print(f'{len(trainingData.era.unique())} UNIQUE ERAS: {trainingData.era.unique()}\\n')\n",
        "print(f'{len(trainingData.data_type.unique())} UNIQUE DATA TYPE: {trainingData.data_type.unique()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print Tournament Data\n",
        "tournamentData.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find Unique Items Within Tournament Data\n",
        "print(f'{len(tournamentData.data_type.unique())} UNIQUE DATA TYPE: {tournamentData.data_type.unique()}\\n')\n",
        "print(f'{len(tournamentData.era.unique())} UNIQUE ERAS: {tournamentData.era.unique()}')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5Lom0GiDRqb"
      },
      "source": [
        "# Select Validation Data Out of Tournament Dataset\n",
        "validationData = tournamentData[tournamentData.data_type=='validation']\n",
        "\n",
        "# Select Test Data Out of Tournament Dataset\n",
        "testData = tournamentData[tournamentData.data_type=='test']\n",
        "\n",
        "# Select Live Data Out of Tournament Dataset\n",
        "liveData = tournamentData[tournamentData.data_type=='live']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"UNIQUE TRAINING TARGETS: {trainingData.target[trainingData.data_type=='train'].unique()}\")\n",
        "print(f\"UNIQUE VALIDATION TARGETS: {tournamentData.target[tournamentData.data_type=='validation'].unique()}\")\n",
        "print(f\"UNIQUE TEST TARGETS: {tournamentData.target[tournamentData.data_type=='test'].unique()}\")\n",
        "print(f\"UNIQUE LIVE TARGETS: {tournamentData.target[tournamentData.data_type=='live'].unique()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot heatmap of feature correlation\n",
        "plt.figure(figsize=(30,30))\n",
        "sns.heatmap(trainingData.corr())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract era numbers\n",
        "trainingData[\"erano\"] = trainingData.era.str.slice(3).astype(int)\n",
        "plt.figure(figsize=[14, 6])\n",
        "trainingData.groupby(trainingData['erano'])[\"target\"].size().plot(title=\"Era sizes\", figsize=(14, 8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feats = [f for f in trainingData.columns if \"feature\" in f]\n",
        "plt.figure(figsize=(15, 5))\n",
        "sns.histplot(pd.DataFrame(trainingData[feats].std()),bins=100)\n",
        "plt.legend([\"Train\"], fontsize=20)\n",
        "plt.title(\"Standard deviations over training features in the data\", weight='bold', fontsize=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feats = [f for f in trainingData.columns if \"feature\" in f]\n",
        "plt.figure(figsize=(15, 5))\n",
        "sns.histplot(pd.DataFrame(validationData[feats].std()),bins=100)\n",
        "plt.legend([\"Val\"], fontsize=20)\n",
        "plt.title(\"Standard deviations over validation features in the data\", weight='bold', fontsize=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feats = [f for f in trainingData.columns if \"feature\" in f]\n",
        "plt.figure(figsize=(15, 5))\n",
        "sns.histplot(pd.DataFrame(testData[feats].std()), bins=100)\n",
        "plt.legend([\"Test\"], fontsize=20)\n",
        "plt.title(\"Standard deviations over test features in the data\", weight='bold', fontsize=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feats = [f for f in trainingData.columns if \"feature\" in f]\n",
        "plt.figure(figsize=(15, 5))\n",
        "sns.distplot(pd.DataFrame(trainingData[feats].std()),bins=100)\n",
        "sns.distplot(pd.DataFrame(validationData[feats].std()),bins=100)\n",
        "sns.distplot(pd.DataFrame(testData[feats].std()), bins=100)\n",
        "plt.legend([\"Train\", \"Val\", \"Test\"], fontsize=20)\n",
        "plt.title(\"Standard deviations over all features in the data\", weight='bold', fontsize=20)"
      ]
    },
    {
      "source": [
        "# 5. Feature Engineering"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Feature Correlation With Target Based On Era\n",
        "\n",
        "# Extract Unique Eras From Training Data\n",
        "eras = list(trainingData.era.unique())\n",
        "eraList = []\n",
        "for era in eras:\n",
        "    eraData = trainingData[trainingData.era==era]\n",
        "\n",
        "    # Calculate Correlations With Target\n",
        "    eraCorr = eraData.corr()\n",
        "    corrWithTarget = eraCorr[\"target\"].T.apply(abs).sort_values(ascending=False)\n",
        "\n",
        "    # Select Features With Highest Correlation To The Target Variable\n",
        "    features = corrWithTarget[:20]\n",
        "    features.drop(\"target\", inplace=True)\n",
        "\n",
        "    featureList = features.tolist()\n",
        "    eraList.append(featureList)\n",
        "\n",
        "    # # Write To A File\n",
        "    # with open(\"Correlations.txt\",'a') as f:\n",
        "    #     f.write(f\"Top 10 Features in {era} according to correlation with target:\\n\")\n",
        "    #     f.write(f'{features[:10]}\\n\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "eraCorrList, topEras = [], []\n",
        "\n",
        "for (era, corrs) in zip(eras, eraList):\n",
        "    # Find Correlation Average Based On Era\n",
        "    corrTot = 0\n",
        "    for corr in corrs:\n",
        "        corrTot += corr\n",
        "    corrAVG = corrTot / len(corrs)\n",
        "    eraCorrList.append([era, corrAVG])\n",
        "\n",
        "# Sort Era Correlation List By Correlation Average\n",
        "eraCorrList.sort(key=lambda eraCorrList: eraCorrList[1], reverse=True)\n",
        "\n",
        "# Select The Top Correlated Eras\n",
        "for i in range(len(eraCorrList)):\n",
        "    if i == 20:\n",
        "        break\n",
        "    topEras.append(eraCorrList[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create New Training Data Set\n",
        "headers = [h for h in trainingData.columns]\n",
        "dataFrameList = [pd.DataFrame(columns=headers)]\n",
        "for eras in topEras:\n",
        "    df = trainingData[trainingData.era==eras]]\n",
        "    dataFrameList.append(df)\n",
        "# eras = [era for era in topEras]\n",
        "# print(f\"[{time.asctime()}] Creating new training data set based on top correlated features.\")\n",
        "# trainingDataEng = pd.concat([trainingDataEng,trainingData[trainingData.era==eras]],axis=1)\n",
        "# print(f\"[{time.asctime()}] Finished creating new training data set based on top correlated features.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainingDataEng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "interactions = preprocessing.PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
        "\n",
        "interactions.fit(trainingData[featureList], trainingData[\"target\"])\n",
        "\n",
        "X_train_interact = pd.DataFrame(interactions.transform(trainingData[featureList]))\n",
        "\n",
        "train=pd.concat([trainingData,X_train_interact],axis=1)\n",
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select Features From Training Data\n",
        "trainingDataX = to_categorical(trainingDataEng[trainingDataEng.columns[trainingDataEng.columns.str.startswith('feature')]])\n",
        "\n",
        "# Select Targets From Training Data\n",
        "trainingDataY = trainingData[trainingData.columns[trainingData.columns.str.startswith('target')]]\n",
        "\n",
        "# Converrt to numpy arrays\n",
        "trainingDataX = np.array(trainingDataX)\n",
        "trainingDataY = np.array(trainingDataY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split Up Data\n",
        "xTrain, xTest, yTrain, yTest = train_test_split(trainingDataX, trainingDataY, test_size = 0.25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsow0byDDidK"
      },
      "source": [
        "# 6. Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instantiate model with 1000 decision trees\n",
        "rf = RandomForestRegressor(n_estimators = 1000, verbose=1, random_state=42, n_jobs=-2)\n",
        "\n",
        "# Train the model on training data\n",
        "rf.fit(xTrain, yTrain.flatten())"
      ]
    },
    {
      "source": [
        "# 7. Validation"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "validationDataX = validationData[feature_list]\n",
        "validationDataX = to_categorical(validationDataX[validationDataX.columns[validationDataX.columns.str.startswith('feature')]])\n",
        "\n",
        "validationDataY = validationData[validationData.columns[validationData.columns.str.startswith('target')]]\n",
        "validationDataX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = rf.predict(validationDataX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "validationDataY.values.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cSyUnlmmG1Z"
      },
      "source": [
        "# 8. Generate Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Performance metrics\n",
        "errors = abs(predictions - validationDataY)\n",
        "print('Metrics for Random Forest Trained on Expanded Data')\n",
        "print('Average absolute error:', round(np.mean(errors), 2), 'degrees.')\n",
        "# Calculate mean absolute percentage error (MAPE)\n",
        "mape = np.mean(100 * (errors / test_labels))\n",
        "# Compare to baseline\n",
        "improvement_baseline = 100 * abs(mape - baseline_mape) / baseline_mape\n",
        "print('Improvement over baseline:', round(improvement_baseline, 2), '%.')\n",
        "# Calculate and display accuracy\n",
        "accuracy = 100 - mape\n",
        "print('Accuracy:', round(accuracy, 2), '%.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# predictions must have an `id` column and a `prediction_kazutsugi` column\n",
        "predictions_df = tournament_data[\"id\"].to_frame()\n",
        "predictions_df[\"prediction_kazutsugi\"] = predictions\n",
        "predictions_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload your predictions\n",
        "predictions_df.to_csv(\"predictions.csv\", index=False)\n",
        "submission_id = napi.upload_predictions(\"predictions.csv\", model_id=model_id)"
      ]
    },
    {
      "source": [
        "# 9. Works Cited\n",
        "- https://tit-btcqash.medium.com/a-comprehensive-guide-to-competing-at-numerai-70b356edbe07\n",
        "- https://towardsdatascience.com/random-forest-in-python-24d0893d51c0\n",
        "- https://realpython.com/python-timer/\n",
        "- https://www.kaggle.com/carlolepelaars/how-to-get-started-with-numerai\n",
        "- https://medium.com/machine-learning-in-practice/cheat-sheet-of-machine-learning-and-python-and-math-cheat-sheets-a4afe4e791b6\n",
        "- https://towardsdatascience.com/a-guide-to-the-hardest-data-science-tournament-on-the-planet-748f46e83690\n",
        "- https://towardsdatascience.com/improving-random-forest-in-python-part-1-893916666cd\n",
        "- https://www.geeksforgeeks.org/python-flatten-a-2d-numpy-array-into-1d-array/\n",
        "- https://docs.numer.ai/tournament/learn\n",
        "- https://forum.numer.ai/t/advice-from-the-kaggle-which-ive-found-very-useful/300\n",
        "- https://forum.numer.ai/t/model-diagnostics-feature-exposure/899\n",
        "- https://towardsdatascience.com/data-correlation-can-make-or-break-your-machine-learning-project-82ee11039cc9\n",
        "- https://www.geeksforgeeks.org/python-sort-list-of-list-by-specified-index/\n",
        "- "
      ],
      "cell_type": "markdown",
      "metadata": {}
    }
  ]
}